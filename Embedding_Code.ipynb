{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2b32c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# sentence-transformers ì„¤ì¹˜\n",
    "!pip install -q sentence-transformers\n",
    "\n",
    "# tqdm (ì§„í–‰ë¥  í‘œì‹œìš©)\n",
    "!pip install -q tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7a188",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 1ï¸âƒ£ GPU ì‚¬ìš© í™•ì¸\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2ï¸âƒ£ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = SentenceTransformer(\"nlpai-lab/KURE-v1\", device=device)\n",
    "\n",
    "# 3ï¸âƒ£ íŒŒì¼ ê²½ë¡œ ì„¤ì • (Google Drive ì—°ë™ ì‹œ ê²½ë¡œ ë³€ê²½ ê°€ëŠ¥)\n",
    "input_file = \"/content/chunked_label.jsonl\"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ\n",
    "output_file = \"/content/chunked_label_embedded.jsonl\"\n",
    "\n",
    "# 4ï¸âƒ£ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„¤ì • (GPU ê¶Œì¥: 128~256)\n",
    "batch_size = 128\n",
    "\n",
    "# 5ï¸âƒ£ ì¤‘ê°„ ì €ì¥ ë‹¨ìœ„ (ëª‡ ê°œì”© íŒŒì¼ì— ì“°ë©´ì„œ ì €ì¥í• ì§€)\n",
    "save_every = 1024  # ë°°ì¹˜ ìˆ˜ ê¸°ì¤€, í•„ìš”ì‹œ ì¡°ì ˆ\n",
    "\n",
    "# 6ï¸âƒ£ ì„ë² ë”© ì§„í–‰\n",
    "batch_texts, batch_records = [], []\n",
    "total_processed = 0\n",
    "\n",
    "# UTF-8 ê¹¨ì§ ë°©ì§€\n",
    "with open(input_file, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile, \\\n",
    "     open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    # ì „ì²´ ë¼ì¸ ìˆ˜ ê³„ì‚° (ì§„í–‰ë°”ìš©)\n",
    "    total_lines = sum(1 for _ in open(input_file, \"r\", encoding=\"utf-8\", errors=\"ignore\"))\n",
    "    infile.seek(0)\n",
    "\n",
    "    for line in tqdm(infile, total=total_lines, desc=\"Embedding\"):\n",
    "        record = json.loads(line.strip())\n",
    "        batch_texts.append(record.get(\"answer_text\", \"\"))\n",
    "        batch_records.append(record)\n",
    "\n",
    "        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„ë² ë”©\n",
    "        if len(batch_texts) == batch_size:\n",
    "            embeddings = model.encode(batch_texts, convert_to_numpy=True)\n",
    "            for rec, emb in zip(batch_records, embeddings):\n",
    "                rec[\"embedding\"] = emb.tolist()\n",
    "                outfile.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            total_processed += len(batch_texts)\n",
    "            batch_texts, batch_records = [], []\n",
    "\n",
    "            # ì¤‘ê°„ ì§„í–‰ ìƒí™© ì¶œë ¥\n",
    "            if total_processed % (batch_size * save_every) == 0:\n",
    "                print(f\"ğŸ’¾ {total_processed} records embedded and saved...\")\n",
    "\n",
    "    # ë§ˆì§€ë§‰ ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬\n",
    "    if batch_texts:\n",
    "        embeddings = model.encode(batch_texts, convert_to_numpy=True)\n",
    "        for rec, emb in zip(batch_records, embeddings):\n",
    "            rec[\"embedding\"] = emb.tolist()\n",
    "            outfile.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "        total_processed += len(batch_texts)\n",
    "\n",
    "print(f\"âœ… ì„ë² ë”© ì™„ë£Œ! ì´ {total_processed}ê°œ ë ˆì½”ë“œ ì²˜ë¦¬. ê²°ê³¼ íŒŒì¼: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
